{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [Global102] Lab III: Analyzing the Data we Collected!\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "### Professor: Tiffany Page\n",
    "\n",
    "In Lab 3, you will import the data set our class created through our survey project, clean that data, analyze it, create visualizations and interpret that data. You are encouraged to work on this in small groups.\n",
    "\n",
    "\n",
    "\n",
    "Estimated Time: 2 hours\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 1: The Jupyter Notebook <a id='section 0'></a>\n",
    "\n",
    "Before we start our lab, we want to give you a brief introduction to Jupyter Notebooks (like this one) where you will work on conducting your survey analysis. \n",
    "\n",
    "**Jupyter notebooks** are documents that can contain a seamless compilation of text, code, visualizations, and more. A notebook is composed of two types of rectangular **cells**:  markdown and code. A **markdown cell**, such as this one, contains text. A **code cell** contains code. All of the code in this notebook is in a programming language called **Python**. You can select any cell by clicking it once. After a cell is selected, you can navigate the notebook using the up and down arrow keys or by simply scrolling.\n",
    "\n",
    "### 1.1 Run a cell <a id='subsection 0a'></a>\n",
    "To run a code cell once it's been selected, \n",
    "- press `Shift` + `Enter`, or\n",
    "- click the Run button in the toolbar at the top of the screen. \n",
    "\n",
    "If a code cell is running, you will see an asterisk (\\*) appear in the square brackets to the left of the cell. Once the cell has finished running, a number corresponding to the order in which the cell was run will replace the asterisk and any output from the code will appear under the cell."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Writing Comments in a cell <a id='subsection 0b'></a>\n",
    "You'll notice that many code cells contain lines of blue text that start with a `#` (like the one above). These are *comments*. Comments often contain helpful information about what the code does or what you are supposed to do in the cell. The leading `#` tells the computer to ignore the rest of the line.\n",
    "\n",
    "### 1.3 Editing a cell <a id='subsection 0c'></a>\n",
    "\n",
    "**Question 1.3.1** You can edit a Markdown cell by clicking it twice. Text in Markdown cells is written in [**Markdown**](https://daringfireball.net/projects/markdown/), a formatting syntax for plain text, so you may see some funky symbols when you edit a text cell. Once you've made your changes, you can exit text editing mode by running the cell. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4 Saving and loading <a id='subsection 0d'></a>\n",
    "\n",
    "#### Saving and Loading\n",
    "\n",
    "Your notebook can record all of your text and code edits, as well as any graphs you generate or calculations you make. You can save the notebook in its current state by clicking `Control-S`/`Command-S`, clicking the **floppy disc icon** in the toolbar at the top of the page, or by navigating to **File > Save and Checkpoint** in the menu bar.\n",
    "\n",
    "The next time you open the notebook, it will look the same as when you last saved it.\n",
    "\n",
    "**Note:** After loading a notebook you will see all the outputs (graphs, computations, etc) from your last session, but you won't be able to use any variables you assigned or functions you defined. You can get the functions and variables back by re-running the cells where they were defined – the easiest way is to **highlight the cell where you left off work, then go to Cell > Run all above** in the menu bar. You can also use this menu to run all cells in the notebook by clicking **Run all**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 2: Introduction To Python <a id='section 1'></a>\n",
    "\n",
    "Now that you are comfortable with using Jupyter Notebooks, we also need to learn a programming language to communicate with the computer. \n",
    "\n",
    "**Programming** is giving the computer a set of step-by-step instructions to follow in order to execute a task. It's a lot like writing your own recipe book! In order to communicate with computers, we must talk to them in a way that they can understand us, via a **programming language**. \n",
    "\n",
    "There are many different kinds of programming languages, but we will be using **Python** in this lab because it is concise, simple to read, and applicable in a variety of projects – from web development to mobile apps to data analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Just simply run this cell (Don't worry if you do not understand it)\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 Data types <a id='subsection 1a'></a>\n",
    "Almost all data you will work with broadly falls into two types: numbers and text. \n",
    "\n",
    "**Numerical data** shows up green in code cells and can be positive, negative, or include a decimal."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Text data** (also called *strings*) shows up red in code cells. Strings are enclosed in double or single quotes. Note that numbers can appear in strings.\n",
    "\n",
    "**Note:** In Python, the single quotation mark and double quotation mark can both denote the start and end of a string. A string must start and end with the same type of quotation mark. If your string contains either type of quotation mark, you can either \"escape\" this character using a `\\` or simply surround the string with the other type of quotation mark. Keep in mind that apostrophes are equivalent to single quotation marks. In this lab, we are going to use double quotation \"string\" for consistency. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2  Variables <a id='subsection 1b'></a>\n",
    "Variable is a named place in the computer's memory where a programmer can store data and later retrieve the data using the variable name. We can give variables values using an **assignment statement**. We can retrieve the data anytime using the variable name. This serves a purpose of saving our intermediate result to that variable. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The assignment statement has three parts. On the left is the *variable name* `income`. On the right is the *value* 10. The *equals sign* in the middle tells the computer to assign the value to the name. You'll notice that when you run the cell with the assignment, it doesn't print anything. But, if we try to access `income` and `tax` again in the future, they will have the value we assigned them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also assign strings to variables."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3 Python  List <a id='subsection 1c'></a>\n",
    "\n",
    "In the previous section, we introduced *variables* which can be used to store data. What if we want to store more than one value in a variable? In Python, a `list` is a data structure which contains multiple data items. Lists in Python can be created by just placing a sequence of data inside square brackets `[]`. The data saved in the list must be seperated by commas. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.4 Functions <a id='subsection 1d'></a>\n",
    "A function is a procedure which works a lot like a machine: it takes an input, does something to it, and produces an output. The input is put between brackets and can also be called the _argument_ or _parameter_. Functions can have multiple arguments. Defining functions can be helpful when you find yourself needing to do the same procedure multiple times with slightly different inputs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using a defined function is known as _calling_ a function. To call a function, simply write the name of the function with your input variable in brackets (argument).\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.5 Importing Python Packages <a id='subsection 1e'></a>\n",
    "\n",
    "\n",
    "Most programming involves work that is very similar to work that has been done before. Since writing code is time-consuming, it's good to rely on others' published code when you can.  Rather than copy-pasting, many programming languages allows us to **import packages**. A module is a file with Python code that has defined variables and functions. A Python package is a collection of modules. By importing packages, we are able to use previously written functions in our own code.\n",
    "\n",
    "Run the cell below to import all the packages that we'll use later to conduct our analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this cell to import the following modules \n",
    "\n",
    "from datascience import *\n",
    "from utils import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note:** Most of our data cleaning process will be done by using the funcitons of `Tables` under the module `datascience`. We will learn how to use functions of `Tables` in the next session. However, the datascience module does not have methods that are used to deal with missing values. \n",
    "\n",
    "For this lab, we wrote a module called **Utils** which contains helper functions that are handy to use to deal with missing values, extract substrings, and convert descriptive answers to numerical values, etc. For this lab purpose, your task is to learn how to apply those functions to clean the survey data. You do not have to know exactly how those funtions are written. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 3: Table and Table operations <a id='section 2'></a>\n",
    "\n",
    "### `Table`\n",
    "Now that we have learned the basic knowledge of Python, we can use Python to analyze our dataset. But before getting into that, we need to learn a useful structure that is used to store our data in a clean and organized way.\n",
    "\n",
    "First, let's understand what `Table` are. `Table` are a way of representing tabular data that are part of the `datascience` package that we imported earlier. A `Table` can be viewed in two ways:\n",
    "* a sequence of named columns that each describe a single attribute of all entries in a data set, or\n",
    "* a sequence of rows that each contain all information about a single individual in a data set.\n",
    "\n",
    "\n",
    "### 3.1 Create Tables <a id='subsection 2a'></a>\n",
    "There are two general ways to create a table:\n",
    "1. We can import data from another file and display it as a Table using the `Table().read_table(\"file_name\")` method. We will talk more on this when we try to import our survey dataset below. \n",
    "\n",
    "2. We can also create a table from scratch. For example, let's say we have three lists, one with a list of different flavors of cake, one with a list of their prices, and another one with the rating for each flavor of the cake. Then, we can create a new `Table` with each of these lists as columns with the `.with_columns()` method: \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you want to access specific rows, columns, or cells from the data, that's where `Table` methods come in handy! "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Table methods <a id='subsection 2b'></a>\n",
    "`Table`s in the datascience module have functions associated with them, we call those functions **methods**. (The terms \"method\" and \"function\" are technically not the same thing.) The statement `from datascience import *` imports all the methods included in the datascience package. A `Table` method is just like a function, but it must operate on a `Table`. An example call may look like:\n",
    "\n",
    "`tbl.method(arguments)` \n",
    "\n",
    "\n",
    "**Hint:** `tbl.take([row_indices])` takes in a list of row indices and return the rows associated with those indices.\n",
    "\n",
    "**Note:** The 1st row of a Table in python has index 0, the second row has index 1, and so on. If we want to access the first row of a Table we need to call `tbl.take(0)`. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we only briefly talked about `Table` methods. In the following sections, we are going to learn how to use `Table` methods to clean and analyze our data. \n",
    "\n",
    "**Note:**\n",
    "We understand that it is a little bit hard to understand all of these in one lab for most of the programming beginners. We will be walking you through the data cleaning and wrangling process step by step to make it as easy as possible.\n",
    "\n",
    "Recommended Reading:\n",
    " * [Introduction to tables](https://www.inferentialthinking.com/chapters/03/4/Introduction_to_Tables)\n",
    " * [Data 8 online Textbook: Chapter 3](http://www.inferentialthinking.com/chapters/03/programming-in-python.html)\n",
    " * [datascience.tables documentation](http://data8.org/datascience/tables.html#tables-overview)\n",
    " \n",
    "After this lab, if you still have questions, try reading the `datascience` package documentation for more explanations. For now, let's clean some data!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 4: Acquiring and Cleaning Our Thesis Survey Data <a id='section 3'></a>\n",
    "\n",
    "\n",
    "### Data Context \n",
    "\n",
    "In this section, you'll be working with the data we collected as a class. \n",
    "\n",
    "\n",
    "## 4.1 Import and display the data <a id='subsection 3a'></a>\n",
    "\n",
    "The survey data is saved in a [csv](https://en.wikipedia.org/wiki/Comma-separated_values) file. The `datascience` package has `read_table` method which allows us to read in the data and display it as a table. In general, to import data from a `.csv` file, we write `Table.read_table(\"file_name\")`.\n",
    "\n",
    "**TASK:** Run the cell below to import the csv file `GS102Fall2021Survey_October.csv` which stores our data and display it as a table, and name the table `raw_data`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data = Table.read_table(\"GS102Fall2021Survey_October.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's examine the table `raw_data` to see what data it contains. \n",
    "\n",
    "Calling the `tbl.show(n)` method displays the first a couple of rows of the table. For example,  `raw_data.show(5)` displays the first 5 rows of the table `raw_data`. Additionally, make sure not to call `.show(n)` without an argument, as this will crash your notebook!\n",
    "\n",
    "**TASK:** Display the top five rows of the `raw_data` table. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# show the first five rows of the raw_data table \n",
    "raw_data.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instead of only displaying the top rows of the table, we may want to look at some arbitray range of rows in the table. We can use the `tbl.take()` method. \n",
    "\n",
    "**TASK:** Display the 5th row to the 8th row of the table by running the cell below. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# display the 5th row to the 8th row\n",
    "raw_data.take([4,5,6,7])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Well done! You succesfully displayed the data as a table and now we can manage the data using Table methods! \n",
    "\n",
    "\n",
    "## 4.2 Data Overview <a id='subsection 3b'></a>\n",
    "\n",
    "Now we want to have more information about the data. First, We want to know the size of the table. For this data, the number of rows of the table the number of people who answered the survey (assuming no duplicates). The number of columns corresponds to the number of questions in the survey. In `Table`s  have the property `num_rows`, which tells you how many rows are in a `Table`. (A \"property\" can be thought of as a method that doesn't need to be called by adding parentheses.)\n",
    "\n",
    "Example call: `tbl.num_rows` \n",
    "\n",
    "**TASK:** Run the cell below to print out the number of rows in the table. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print the number of rows in the table \n",
    "num_surveydata_rows = raw_data.num_rows\n",
    "print(\"The table has {} rows in it!\".format(num_surveydata_rows))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similarly, the property `num_columns` returns the number of columns in a table. Example call: `tbl.num_columns` \n",
    "\n",
    "**TASK:** Run the cell below to print out the number of columns in the table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this cell\n",
    "num_farmers_markets_columns = raw_data.num_columns\n",
    "print(\"The table has\", num_farmers_markets_columns, \"columns in it!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Does the number of rows truely represent the number of responses in total in our table? The answer is No! Notice that the first two rows do not contain the actual responses and so are not meaningful for the data analysis we are trying to conduct. We can remove these two rows from the original table. \n",
    "\n",
    "**TASK:** Run the cell below to remove the first two rows from the table, as well as two other rows that have no data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove the first three rows and row 224, 358, 370, 371, 632, 637, 692, 750, 762, 763, 802 from the table raw_data\n",
    "raw_data.exclude([0, 1, 2, 223, 357, 369, 370, 631, 636, 691, 749, 761, 762, 801])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What you just did is actually is one of the steps of the data cleaning and wrangling process! \n",
    "\n",
    "##  4.3 Data  Cleaning and Wrangling <a id='subsection 3c'></a>\n",
    "\n",
    "\n",
    "When we get the raw data from the survey results online, we should ask ourselves: \n",
    "\n",
    "* What data do we have and what data do we need for analysis? \n",
    "* Are there inconsistencies and missing values in the data?\n",
    "* How do we better organize the data for analysis? \n",
    "\n",
    "These questions bring the following two terms: Data Cleaning and Data Wrangling\n",
    "\n",
    "### Data Cleaning \n",
    "Data is the backbone of data analysis. In order to successfuly analyze data, it must be in a clean and easily interpretable format so that we don't run into inconsistencies or errors later in the process. Regarding the survey data, we might encounter non-serious participants (who choose the first answer for all questions), missing values, duplications, and so on. To perform the data analytics properly we need various data cleaning techniques so that our data is ready for analysis. \n",
    "\n",
    "\n",
    "### Data Wrangling\n",
    "[Data wrangling](https://en.wikipedia.org/wiki/Data_wrangling), sometimes referred to as data munging, is the process of transforming and mapping data from one \"raw\" data form into another format with the intent of making it more appropriate and valuable for a variety of downstream purposes.\n",
    "\n",
    "Let's get started!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3.1  Obtain a smaller table\n",
    "\n",
    "You should notice that the table has a huge number of columns! Often times, the original dataset contains some information that is not relevant for the questions we are asking. If we're not interested in some information in the original table, too many columns can make the table difficult to read. Thus, obtaining a smaller table containing only the relevant information we need to conduct our analysis is important. \n",
    "\n",
    "In our data set, the top two rows are not survey responses so we do not want to include them in the table and we wanted to cut two rows that had no responses (we did this step above!). In such situations, you might want to ceate a smaller table only with rows and columns that you want to analyze. \n",
    "\n",
    "\n",
    "\n",
    "#### 4.3.1.1 Drop unnecessary rows\n",
    "\n",
    "We talked about removing the first two rows using `tbl.exclude` method above. The `exclude` method removes a row or multiple rows of a table in place. The method takes in one argument, which indicates which row(s) to remove from the table. The `exclude` method does not modify the original table, and instead returns a new table with those rows removed. Search `Table.exclude()` in the [documentation of `exclude`](http://data8.org/datascience/_autosummary/datascience.tables.Table.exclude.html) for more information.\n",
    "\n",
    "**Note:** In order to save the change you made to the table, you need to name the returned new table. Here, we use `cleaned_data` to distinguish the new table from the original one.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_data = raw_data.exclude([0, 1, 2, 223, 357, 369, 370, 631, 636, 691, 749, 761, 762, 801])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note:**\n",
    "From now on, we will use `cleaned_data` and update it at each step. The data we read in the beginning, `raw_data`, is still exactly the same as when we loaded it. \n",
    "\n",
    "#### 4.3.1.2 Select Columns \n",
    "\n",
    "We can use the `Table` method `tbl.select(column_names)` to choose only the columns that we want from `tbl`. It takes any number of arguments, as long as all are column names in our table. This method returns a new table with only those columns in it. *The columns are in the order in which they were listed as arguments*. Check the documentation of [Table.select](http://data8.org/datascience/_autosummary/datascience.tables.Table.select.html) for more detailed information. \n",
    "\n",
    "**TASK:** Run the cell below to get a table containing only two columns: 'Q11' and 'Q2'. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is just an example to show how to obtain a new table with two columns 'Q11', 'Q2'\n",
    "cleaned_data.select(\"Q11\", \"Q2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this survey, the first 11 columns don’t have information we need in them. We will select just the columns with data we want (Q2, Q3, Q4, Q5, Q6, Q7, Q8, Q9, Q10, Q11, Q12, Q12.1, Q13, Q14, Q15). Use `select` to create a table with only those questions from `cleaned_data` and update the `cleaned_data` by assigning the new table to it. \n",
    "\n",
    "**TASK:** Run the following cell to generate the table with only the columns we need. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select the columns that we are going to use to analyze the survey data and put those names into a list \n",
    "columns = ['Q2', 'Q3', 'Q4', 'Q5', 'Q6', 'Q7', 'Q8', 'Q9', 'Q10', 'Q11', 'Q12','Q12.1','Q13', 'Q14',\n",
    "            'Q15']\n",
    "\n",
    "cleaned_data = cleaned_data.select(columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's take a look at the number of rows and columns of the smaller table. Also, you might find that the `tbl.labels` helpful for checking the name of all columns in the smaller table. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run the cell to display the information of the new table \n",
    "print(\"There are total {} rows in the cleaned_data.\".format(cleaned_data.num_rows))\n",
    "print(\"There are total {} columns in the cleaned_data. \\n\".format(cleaned_data.num_columns))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Section 4.3.1 Recap:** \n",
    "\n",
    "So far, we have finished creating a smaller data table called `cleaned_data` by:\n",
    "1. Removing the four rows that we do not need for our analysis \n",
    "2. Selecting 11 columns from the raw data \n",
    "\n",
    "If you have finished everything above, remember to make sure you run through each cell above before entering into the next section of this notebook. To do that, click the cell below and go to the menu bar at the top of the screen click **Cell > Run All Above**. After doing that, let's take a look at the top five rows of our `cleaned_data` table so far. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# display the top five rows of the smaller table\n",
    "cleaned_data.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3.2 Missing Values \n",
    "\n",
    "Some of the values in this table may be missing, denoted by `nan`. This stands for \"Not a Number,\" and this means that the student who filled out the survey did not give a response to this question. You may also see missing values appear as `NA` or `None`. Usually, `NaN`s are stored as a distinct data type (i.e. not a number or a string), but the `datascience` package converts them all to strings when we read in our data.\n",
    "\n",
    "#### Exercise 4.3.2.1: Calculate missing value proportion for each question\n",
    "\n",
    "**TASK:** Firstly, let's convert all the `nan` strings in the `cleaned_data` table to `None` by running the following funciton from the `utils` module. We do this conversion because `None` objects are easier to handle using functions of the `utils` module. \n",
    "\n",
    "**Notes on the Survey Design:** When you design your own survey, it is better to use \"None of above\" rather than \"None\" as a choice to indicate none of the given choices is applicable. Since in the Table, both string \"None\" and python `None` objects look the same in a Jupyter notebook table. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# convert the string 'nan' to Python None object\n",
    "cleaned_data = encode_nans_table(cleaned_data)\n",
    "cleaned_data.show(50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we want to know if the data collected from the survey is sufficient, we might want to know what is the proportion of missing values for each survey question, let's call it **missing proportion** in this notebook. \n",
    "\n",
    "**TASK:** Calculate the proportion of missing values for each question included in the `cleaned_data` table and display the result in a table. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# calculate the missing values for each question (column) in the cleaned_data table \n",
    "# and display the result in a table \n",
    "missing_prop = np.array([float(missing_proportion(cleaned_data, column)) for column in columns])\n",
    "missing_prop_tbl = Table().with_columns([\"questions\", columns,\n",
    "                                 \"missing_prop\", missing_prop])\n",
    "missing_prop_tbl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercise 4.3.2.2: Sort the missing proportion in descending order\n",
    "\n",
    "\n",
    "The table above shows the missing proportion for each question in `cleaned_data` table. We want to detect questions that have a large missing proportion. To do that, we can sort the missing proportion column and make it show the largest value on top. \n",
    "\n",
    "The Table method `tbl.sort(column)` takes in a column name that you want the table to sorted by. By default, this method will sort in _ascending_ order. By adding in an optional argument, `descending = True`, we tell the method that we want our output to be in descending order.\n",
    "\n",
    "**Note:** Rows always stick together when a table is sorted.\n",
    "\n",
    "**TASK:** Sort the `missing_prop_tbl` table by missing proportion (the `missing_prop` column) in descending order.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_prop_tbl.sort(\"missing_prop\", descending = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Section 4.3.2 Recap:** \n",
    "\n",
    "We calculated the missing proportion for each column in the table and displayed the missing proportion in a descending order in order to find the columns with the largest amount of missing values. The overall missing proportion of our data is reasonable and the response proportion for the survey data is good. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Section 4.3 Recap\n",
    "\n",
    "In section 4.3, we did data cleaning and data wrangling, which are the two essential and fundamental parts of data analysis. \n",
    "* We created a smaller table by selecting columns we need and dropping rows we do not need from the original table. \n",
    "* We explored and analyzed missing values in the table. \n",
    "\n",
    "Below, we give a Summary of `Table` methods that we used through this notebook:\n",
    "\n",
    "### Summary of `Table` methods ###\n",
    "\n",
    "    \n",
    "|Name|Example|Purpose|\n",
    "|-|-|-|\n",
    "|`Table`|`Table()`|Create an empty table, usually to extend with data|\n",
    "|`Table.read_table`|`Table.read_table(\"my_data.csv\")`|Create a table from a csv file|\n",
    "|`with_columns`|`tbl = Table().with_columns(\"cake price\", [2, 4.5], \"cake name\", [\"chocolate\", \"straberry\"]`|Create a copy of a table with more columns|\n",
    "|`sort`|`tbl.sort(\"cake price\")`|Create a copy of a table sorted by the values in a column|\n",
    "|`where`|`tbl.where(\"cake price\", are.above(2))`|Create a copy of a table with only the rows that match some *predicate*|\n",
    "|`num_rows`|`tbl.num_rows`|Compute the number of rows in a table|\n",
    "|`num_columns`|`tbl.num_columns`|Compute the number of columns in a table|\n",
    "|`select`|`tbl.select(\"column name\")`|Create a copy of a table with only some of the columns|\n",
    "|`drop`|`raw_data.exclude([row_indices]))`|Create a copy of a table without some of the rows|\n",
    "|`take`|`tbl.take([row_indices])`|Create a copy of the table with only the rows whose indices are in the given array|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summary of `utils` functions ###\n",
    "\n",
    "    \n",
    "|Name|Example|Purpose|\n",
    "|-|-|-|\n",
    "|`encode_nans`|`encode_nans(table, column_name)`|Converts \"nan\" strings in the column_name to `None`|\n",
    "|`encode_nans_table`|`encode_nans_table(table)`|Converts all \"nan\" strings in a `Table` to `None`|\n",
    "|`get_first_selection`|`get_first_selection(table, column_name)`|Keep the first selection for a question|\n",
    "|`get_mixed_category`|`get_mixed_category(table, column_name, string)`|Create a 'Mixed string' category|\n",
    "|`missing_proportion`|`missing_proportion(table, column_name)`|Calculate the proportion of missing values in a column|\n",
    "|`drop_nonserious_rows`|`drop_nonserious_rows(table, column_name)`|Delete the non-serious responses in the survey|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.4 Saving `cleaned_data` to a new CSV file <a id='subsection 3d'></a>\n",
    "\n",
    "Congratulations! You have finished the first part of the survey analysis. In this notebook, you learned about Jupyter notebooks, Python programming, `Table`s, data cleaning, and data wrangling. Before moving on, let's save our `cleaned_data` into a `.csv` file so that we can easily import it into the next notebook. The function `tbl.to_csv(\"filename.csv\")` saves the tbl as a `.csv` file called `filename.csv`. \n",
    "\n",
    "**TASK:** Save the table `cleaned_data` into a csv file called `cleaned_data.csv`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_data.to_csv(\"cleaned_GS102Fall2021Survey_October.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Dependencies: (Run the cell below before continuing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datascience import *\n",
    "from utils import *\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "%matplotlib inline\n",
    "sns.set()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1 The Data <a id = 'section0'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = Table().read_table('cleaned_GS102Fall2021Survey_October.csv')\n",
    "data.show(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.1 Relationship between demographic factors and how time at Berkeley has impacted environmental consciousness <a id = 'section1'></a>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Displaying Rows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's get an idea of the data we're working with.\n",
    "\n",
    "TASK: Use the .select method to display only the columns pertaining to gender and online shopping.\n",
    "\n",
    "Remember that you can use Python's lists ([x, y]) to select more than one column at once. Save this new table into a name called gender_online_shopping."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# previous cleaning did not capture all the nans, so we'll manually remove these rows \n",
    "for col in columns: \n",
    "    data = data.where(col, are.not_equal_to(\"nan\")) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "major_time_berkeley = data.select(['Q12', 'Q2'])\n",
    "major_time_berkeley"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"The proportion of missing values in the first column is: {}\".format(missing_proportion(major_time_berkeley, 'Q12')))\n",
    "print()\n",
    "print(\"The proportion of missing values in the second column is: {}\".format(missing_proportion(major_time_berkeley, 'Q2')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pivot Tables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pivot tables (also known as Contingency Tables) are data structures that allow us to summarize key points in our dataset. In our case, we are trying to look at the relationship between major and how time at Berkeley has impacted environmental consciousness. Our independent variable, or the variable that we believe might influence the other is major. This variable should be presented along the columns of our pivot table. The dependent variable should be placed along the rows of the pivot table. The data within the table will be counts of major-how time at Berkeley pairs.\n",
    "\n",
    "TASK: Use the Table method .pivot to create a pivot table between major and how time at Berkeley has impacted environmental consciousness. This method takes in two arguments: the column name to be displayed along the columns, and the column name to be displayed along the rows. Save the resulting pivot table into a name called pivoted_major_time_berkeley."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pivoted_major_time_berkeley = major_time_berkeley.pivot('Q12', 'Q2')\n",
    "pivoted_major_time_berkeley"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at the distribution of respondents across major, gender, race/ethnicity, year in school, transfer status, and living location. First we will look at race."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (18, 6))\n",
    "plt.rcParams.update({'font.size': 15})\n",
    "ax=sns.barplot(x = data.group('Q13').column('Q13'), y = data.group('Q13').column('count')); # Run this cell\n",
    "plt.xlabel('Race/Ethnicity')\n",
    "plt.ylabel('Counts')\n",
    "plt.title('Race/Ethnicity of Students in Survey'); \n",
    "\n",
    "# To display count labels: \n",
    "# 1. set sns.barplot to ax (above)\n",
    "# 2. use code below as template - you can adjust the numbers in ax.text to move/center labels\n",
    "counts = data.group('Q13').column('count');\n",
    "for i, p in enumerate(ax.patches):\n",
    "    height = p.get_height();\n",
    "    ax.text(p.get_x() + p.get_width() / 2, height + 1, counts[i], ha=\"center\");\n",
    "            \n",
    "plt.xticks(rotation=90);\n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Task:** generate a bar chart for gender, major, transfer status, year in school and living location. If you go to the menu bar at the top of the page, select the Insert drop-down menu and select Insert Cell Below you will be able to add an empty cell. Then copy and paste the code above, but change the variable names, x-axis label and the title of the bar chart to reflect the variable you are charting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What do you notice about the distribution of respondents across gender, race/ethnicity, major, year in school, transfer status and living location?\n",
    "\n",
    "**Answer:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**How representative is our sample?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In these bar charts we can see the total number of respondents by race/ethnicity, gender and major. With this information you can determine how representative of the larger population our sample is across these categories. Calculate the percentage of respondents for each race/ethnicity category and compare that to the larger population by finding that information on this website: https://opa.berkeley.edu/campus-data/uc-berkeley-quick-facts. Remember we are just interested in the UCB undergraduate population, not all UCB students. Here's the website with data on majors: https://opa.berkeley.edu/sites/default/files/ugprofile_2016-17_11april2018.pdf\n",
    "\n",
    "Percent by race/ethnicity category in our survey sample.\n",
    "\n",
    "**Answer:**\n",
    "\n",
    "\n",
    "How do these percentages compare to the larger population? Is our sample representative along the lines of race/ethnicity?\n",
    "\n",
    "**Answer:**\n",
    "\n",
    "What should we be careful making claims about and why (based on our sample)?\n",
    "\n",
    "**Answer:**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Task** Add some additional cells and repeat this for gender and major. Be sure to answer all three questions above for gender and major as well."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6.2: Processing Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In data science, when you repeat a set of tasks to analyze a dataset, you are creating a *data processing pipeline*. \n",
    "\n",
    "We will write a function that takes in a table, two column names of categorical variables in the table, a title, and a category, and outputs a bar graph displaying the relationship between those variables. The first column name is the independent variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def categorical_variable_relationship(table, first, second, title, category):\n",
    "    table = table.select([first, second])\n",
    "    table = drop_missing_rows(table, first)\n",
    "    table = drop_missing_rows(table, second)\n",
    "    pivot = table.pivot(first, second)\n",
    "    proportion_pivot = counts_to_proportions(pivot)\n",
    "    plot_bar_chart(proportion_pivot, proportion_pivot.labels[1:], title, category)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TASK:** Using your newly created `categorical_variable_relationship` function, plot a bar chart to find the relationship between Race/Ethnicity **'Q13'** and Clubs 'Q4'**. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_variable_relationship(data,\n",
    "'Q13', 'Q4', 'Relationship between Race/Ethnicity and Clubs',\n",
    "                                  'Race/Ethnicity')\n",
    "plt.xlabel(\"Involved in Organization/Club\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Interpret the bar chart** What do you see that is interesting? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Task** Add some blank cells and repeat this with gender and clubs. Create the bar chart and interpret it. Then select 4 other variable combinations of your choice, create the bar charts and interpret them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7.1 Significance Tests for Categorical Variables <a id = 'section2'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At this point, you should have identified some differences along the lines of gender, race/ethnicity, major, year in school, transfer student status and/or living location. However, how do we know that these differences are not due to *random chance* alone? To answer this question, we turn to **hypothesis testing** for categorical variables. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hypothesis Testing: The Basics <a id = 'subsection2a'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hypothesis tests are used when you observe some phenomena and want to know whether it happened by random chance alone or due to a specific cause. A hypothesis is a guess about the world, based on available evidence. We want to test between two different hypotheses:\n",
    "\n",
    "The Null Hypothesis: My observation has arisen due to random chance alone.\n",
    "The Alternative Hypothesis: My observation has arisen due to a cause other than random chance alone."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chi-square Testing: Introduction and Case Study <a id = 'subsection2b'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Chi-square Test is a type of hypothesis test that works well with categorical data. It measures how well the observed distribution of data fits with the distribution that is expected if the variables are independent. (Light, 2008) We need to convert our table data into a pivot table before we can conduct the chi-squared test.\n",
    "We need to use counts instead of proportions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Pivoting the Data\n",
    "\n",
    "**TASK:** Use the `Table` method `.pivot` with the appropriate ordering of column names. Save this into a name called `gender_mask`. \n",
    "\n",
    "Don't worry about the ordering of values; just make sure to have the correct values on the vertical and horizontal axis. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gender_clubs = data.select(['Q12.1', 'Q4'])\n",
    "gender_clubs\n",
    "pivoted_gender_clubs = gender_clubs.pivot('Q12.1', 'Q4')\n",
    "pivoted_gender_clubs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Adding Row and Column Totals\n",
    "\n",
    "In order to calculate the expected counts under our null hypothesis of independence, we need to calculate row and column totals.\n",
    "\n",
    "**Row totals** are horizontal sums added as the right-most column of the table. In this case, they would represent the total number of respondents by gender identity in the dataset.\n",
    "\n",
    "**Column Totals** are vertical sums added as the bottom row of the table. In our example, they represent the total number of respondents in each category of mask usage.\n",
    "\n",
    "**TASK:** Create a table called `totals` which adds a Row Total and Column Total to the `pivoted_gender_mask` table. Use the function `add_row_totals`, which takes in a pivot table and returns an updated version with the row totals. Also use the function `add_column_totals`, which takes in a pivot table and returns an updated version with the column totals. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "totals = add_row_totals(pivoted_gender_clubs)\n",
    "totals = add_column_totals(totals)\n",
    "totals"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Calculating Expected Counts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We're ready to begin calculating expected counts.\n",
    "\n",
    "Formula:\n",
    "Column Total⋅Row TotalTotal # of Responses\n",
    " \n",
    "PRACTICE\n",
    "\n",
    "1) What is the expected value of female respondents who are in a club?\n",
    "\n",
    "**Answer:**\n",
    "\n",
    "2) What is the expected value of male respondents who are in a club?\n",
    "\n",
    "**Answer**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4: Calculating the Chi-square statistic and interpreting results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once we have both our prepared data table and the expected values corresponding to each entry, we can calculate the chi-square statistic.\n",
    "\n",
    "𝜒2=∑𝑖=1𝑛(𝑂𝑖−𝐸𝑖)2𝐸𝑖\n",
    " \n",
    "Under our null hypothesis of independence, this chi-squared statistic follows a chi-squared distribution. In general, most hypothesis tests involve the calculation of a test statistic, then seeing the probability of observing a more extreme test statistic value given the distribution implied by the null hypothesis. In this case, our null hypothesis implies a chi-squared distribution, which has an additional parameter called degrees of freedom. This parameter is determined by the shape of our pivot table.\n",
    "\n",
    "degrees of freedom=(Number of Columns−1)⋅(Number of Rows−1)\n",
    " \n",
    "For our example, the degrees of freedom is just 1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's break this down.\n",
    "- The Greek letter chi is written $\\chi$. Thus $\\chi^2$ is the symbolic representation of the chi-squared statistic.\n",
    "- The $O_i$ represents an observed count (e.g. the number of female Democrats in the dataset)\n",
    "- The $E_i$ represents an expected count (e.g. expected number of female Democrats given random choice)\n",
    "- The $\\sum_{i=1}^{n}$ represents the summation over all observations \n",
    "\n",
    "In simple terms, we take the following steps to calculate the Chi-square statistic: \n",
    "\n",
    "1) Take the difference between the Observed and Expected counts for each unique group in the sample \n",
    "\n",
    "2) Square that difference and divide it by the expected value for that group\n",
    "\n",
    "3) Add up all those differences \n",
    "\n",
    "4) Find the probability of observing a chi-squared statistic value under the chi-squared distribution."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This might seem like a lot of computation. If doing this computation by hand, you would either have to look up a chi-squared distribution table to find the probability of seeing your chi-squared statistic or use a function that can calculate that for you. Instead, we have provided you a function that can do all these steps for you.\n",
    "\n",
    "TASK: Use the function chisquaretest to calculate the Chi-square statistic. This function takes in a pivot table with added Row and Column Totals."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chisquaretest(totals)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You may have noticed that there is another output called the p-value. This is a number which indicates the likelihood that your observations are consistent with the null hypothesis. In this case, our null hypothesis is that mask usage and gender are independent of each other.\n",
    "\n",
    "By convention, we say that:\n",
    "\n",
    "If the p-value is less than or equal to 0.05 then, we can reject the null hypothesis. Essentially, what we are saying here is that a 1 in 20 chance of observing our test statistic is too unlikely for the null hypothesis to be true.\n",
    "\n",
    "If the p-value is greater than 0.05, then we do not reject the null hypothesis.\n",
    "Rejecting the null hypothesis means that we have evidence that supports the alternative hypothesis. In the case of Chi-square tests, it means that the two variables are inter-related. In either case, notice that we never accept that a hypothesis is true; rather, we simply reject or fail to reject it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TASK:** Based on our p-value, what can we determine about the relationship between gender and involvement in clubs? What can you say about the null hypothesis?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer:** [Click on this cell and write your answer here]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Task:** Add additional empty cells and repeat this for four other variable pairs. What relationships are statistically significant?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Discussion: Correlation vs. Causation <a id = 'subsection2c'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In any class involving statistics, you may have heard the adage, *\"Correlation doesn't imply causation.\"* \n",
    "\n",
    "Let's clarify what that means and why it's so important. *Correlation* is the inter-relation in trends of two variables (ex: gender and political party). Whereas, *Causation* is an explicit statement that a change in one variable directly incites a change in the other variable (ex: smoking and respiratory illness). \n",
    "\n",
    "\n",
    "Let's look at some concrete examples of why correlation isn't the same as causation. For instance, there is a 95.8% correlation between the per capita consumption of mozzarella cheese and the number of Civil Engineering doctorates awarded in the US. Clearly, these are two completely unrelated events that aren't linked to one another. As such, we wouldn't use this correlation as evidence of causality between these variables. \n",
    "\n",
    "For more \"Spurious Correlations\", check out this link: https://www.tylervigen.com/spurious-correlations\n",
    "\n",
    "\n",
    "In our discussion of Chi-square tests in Lab 2, we were able to find that the relationship between certain variables (ie. gender and presidential voting choice) deviated significantly from the null hypothesis. Does this mean that gender *causes* the choice in presidential candidates? No. To establish that relationship, we must gather more evidence.\n",
    "\n",
    "Typically, to establish a causal relationship between variables, you must perform a randomized controlled experiment. If you're interested in this topic, you can check out this link for more information: https://www.statisticssolutions.com/establishing-cause-and-effect/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8.1 Bias in Surveys <a id = 'section6'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The goal of a survey is to provide information about a large population from a limited sample. In this notebook, we've gone quite in depth in how to analyze different variables present in a survey. However, we've operated under the assumption that our survey data was representative of the UC Berkeley student population. However, in the real world, data collection is messy and difficult. Thus, we must be aware of sources of bias that may be present in our data. Here are a few common sources of bias in survey data:\n",
    "\n",
    "Undercoverage bias: Certain groups of the population are left out of the sample, leading to an undercoverage of responses in the sample\n",
    "Nonresponse bias: If the survey is optional, then certain respondents may not complete it. This may lead to skewed data.\n",
    "Self-selection bias: If sample members volunteer themselves to take the survey, it may be the case that they are passionate about the issues asked about. This usually leads to an over-representation of individuals with strong opinions in the survey.\n",
    "\n",
    "**TASK:** Given these sources of bias, do you see any problems with the methodology of our survey? If there are problems, what would you have done differently and why?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer:** [Click on this cell and write your answer here]\n",
    "\n",
    "--------------------------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Good job! You have finished Lab 3: Analyzing the Data we Collected!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bibliography <a id = 'section7'></a>\n",
    "\n",
    "• Caitlin Light - Adapted Chi-square case study. https://www.ling.upenn.edu/~clight/chisquared.htm\n",
    "\n",
    "• Tyler Vigen - Incorporated example of \"spurious\" correlation. https://www.tylervigen.com/spurious-correlations\n",
    "\n",
    "• Statistics Solutions - Referenced section on experimental design. https://www.statisticssolutions.com/establishing-cause-and-effect/\n",
    "\n",
    "• Stat Trek - Adapted material on sources of survey bias. https://stattrek.com/survey-research/survey-bias.aspx\n",
    "\n",
    "Some examples adapted from the UC Berkeley Data 8 textbook:\n",
    "\n",
    "* [Tables](https://www.inferentialthinking.com/chapters/06/Tables.html\")\n",
    "* [Data 8 online Textbook: Chapter 3](http://www.inferentialthinking.com/chapters/03/programming-in-python.html)\n",
    "\n",
    "- [Introduction to tables](https://www.inferentialthinking.com/chapters/03/4/Introduction_to_Tables)\n",
    "\n",
    "\n",
    "Some term explanations adapted from the datascience documentation: \n",
    "\n",
    "- [datascience.tables documentation](http://data8.org/datascience/tables.html#tables-overview)\n",
    "\n",
    "\n",
    "Some ideas in the sections of \"Jupyter Notebook\", \"Introduction to Python\" and \"Tables and Table operations\" adapted from materials in [UC Berkeley Data Science Modules core resources](http://github.com/ds-modules/core-resources):\n",
    "\n",
    "\n",
    "- Shriya Vohra, Scott Lee, Pancham Yadav - intro-module-final\n",
    "- Keeley Takimoto - Intro-to-Python-and-Jupyter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### Getting extra help\n",
    "\n",
    "Interested in more help with learning Python or computational survey analysis? Check out  [Data Peer Consulting](https://data.berkeley.edu/education/data-peer-consulting) in Moffitt library for drop-in, one-on-one questions. For additional workshops designed for people new to computational analysis, take a look at the workshops at [The Dlab](https://dlab.berkeley.edu) (free for Berkeley students!). \n",
    "\n",
    "Good luck!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Note to Students: \n",
    "If you would like to use the utility provided by the Data Science Education Program team, simply copy the utils.py script to the folder where you are creating your analysis notebook. Good luck!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
